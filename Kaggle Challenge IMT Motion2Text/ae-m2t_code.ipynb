{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccc7e7cb-3f6e-4da2-bfb2-076328f3e906",
    "tags": []
   },
   "source": [
    "---\n",
    "## **<p style=\"text-align: center; text-decoration: underline;\">DATA CHALLENGE</p>**\n",
    "# **<p style=\"text-align: center;\">HUMAN MOTION DESCRIPTION (HMD): Motion-To-Text</p>**\n",
    "---\n",
    "\n",
    "> IMT Nord Europe *2025*.\n",
    "\n",
    "---\n",
    "\n",
    "![examples](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fimg.clipart-library.com%2F2%2Fclip-motions%2Fclip-motions-6.png&f=1&nofb=1&ipt=0747ffa645bb5f7798e8a2d44499b28f1156ce0e83b1b300fabfed4c6ab1fdf2&ipo=images)\n",
    "\n",
    "### â–  **Overview**\n",
    "In this data challenge, you will explore the intersection of natural language processing (NLP) and human motion synthesis by working on text-to-motion and motion-to-text tasks using the HumanML3D dataset. This dataset contains 3D human motion sequences paired with rich textual descriptions, enabling models to learn bidirectional mappings between language and motion.\n",
    "\n",
    "#### **I. Main Task: Motion-To-Text Generation**\n",
    "- **Motion-to-Text:** Develop a model to describe human motions in natural language given a sequence of 3D poses.\n",
    "\n",
    "#### **II. Dataset Overview:**\n",
    "- HumanML3D includes 14,616 motion samples across diverse actions (walking, dancing, sports) and 44,970 text annotations.\n",
    "- Data includes skeletal joint positions, rotations, and fine-grained textual descriptions.\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fproduction-media.paperswithcode.com%2Fdatasets%2F446194c5-ce59-43eb-b4cb-570a7a4d0cd9.png&f=1&nofb=1&ipt=b2edbe3251cab88e26a7f9d4e765c811b2cc890dc2ace7f7456baeca076b115b&ipo=images\" alt=\"description\" style=\"width:800px; height:600px;\" />\n",
    "\n",
    "The provided dataset contains the following components:\n",
    "\n",
    "- 1. `motions` Folder: Contains `.npy` files, each representing a sequence of body poses. Each file has a shape of `(T, N, d)`, where:\n",
    "  - `T`: Number of frames in the sequence (varies across sequences).\n",
    "  - `N`: Number of joints in the body (22 in this case).\n",
    "  - `d`: Dimension of each joint (3D coordinates: `x`, `y`, `z`).\n",
    "\n",
    "- 2. `texts` Folder: Contains `.npy` files, each providing **3 textual descriptions** of the corresponding motion sequence. Each description is accompanied by part-of-speech (POS) tags for every word in the description. Example: \"a person jump hop to the right#a/DET person/NOUN jump/NOUN hop/NOUN to/ADP the/DET right/NOUN#\"\n",
    "\n",
    "- 3. File Lists\n",
    "    - **`all.txt`**: List of all motion files in the dataset.\n",
    "    - **`train.txt`**: List of motion files for training.\n",
    "    - **`val.txt`**: List of motion files for validation.\n",
    "    - **`test.txt`**: List of motion files for testing.\n",
    "\n",
    "\n",
    "#### **III. Evaluation Metrics**\n",
    "\n",
    "BLEU (Bilingual Evaluation Understudy): The BLEU score evaluates the quality of generated text against reference texts using n-gram precision.\n",
    "> Note: Higher BLEU scores (closer to 1 or 100\\%) indicate better text-motion alignment. BLEU focuses on lexical overlap, not semantic accuracy. For motion descriptions, it measures how well generated text matches the linguistic patterns of ground-truth annotations.\n",
    "\n",
    "Solutions should be submitted in the following format (in a csv file):\n",
    "\n",
    "For each ID in the motion test set, you must predict the corresponding description. The file should contain a header and have the following format:\n",
    "\n",
    "| id      | text                                                                 |\n",
    "|---------|---------------------------------------------------------------------|\n",
    "| 004822  | A person walks slowly forward, swinging their arms naturally        |\n",
    "| 014457  | Someone performs a golf swing with proper form                      |\n",
    "| 009613  | An individual jogs backwards diagonally across the room             |\n",
    "| 008463  | A man bends down to pick up an object while walking                 |\n",
    "| 012365  | A dancer spins clockwise while raising both arms                    |\n",
    "| 007933  | Two people engage in a slow-motion martial arts demonstration       |\n",
    "| 003430  | A child skips happily across a playground                           |\n",
    "| 014522  | An athlete performs a perfect cartwheel sequence                    |\n",
    "| 005698  | A woman gracefully practices yoga sun salutations                   |\n",
    "| 001664  | A parkour expert vaults over a low wall                             |\n",
    "\n",
    "You can generate your submission files using pandas as follows:\n",
    "\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     'id': ['004822', '014457', ...],\n",
    "    ...     'text': [\n",
    "    ...         \"a person walking slowly\",\n",
    "    ...         \"someone swinging a golf club\",\n",
    "    ...         ...\n",
    "    ...     ]\n",
    "    ... })\n",
    "    ... submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Auto Encoder Motion2Text by Antoine Mariot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:33.291370Z",
     "iopub.status.busy": "2025-01-31T06:08:33.291090Z",
     "iopub.status.idle": "2025-01-31T06:08:33.298292Z",
     "shell.execute_reply": "2025-01-31T06:08:33.297343Z",
     "shell.execute_reply.started": "2025-01-31T06:08:33.291346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:33.781145Z",
     "iopub.status.busy": "2025-01-31T06:08:33.780681Z",
     "iopub.status.idle": "2025-01-31T06:08:33.785088Z",
     "shell.execute_reply": "2025-01-31T06:08:33.784078Z",
     "shell.execute_reply.started": "2025-01-31T06:08:33.781102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importation des donnÃ©es\n",
    "motion_data_dir = './motions'\n",
    "text_data_dir = './texts' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:34.075217Z",
     "iopub.status.busy": "2025-01-31T06:08:34.074944Z",
     "iopub.status.idle": "2025-01-31T06:08:34.089358Z",
     "shell.execute_reply": "2025-01-31T06:08:34.088654Z",
     "shell.execute_reply.started": "2025-01-31T06:08:34.075196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Chargement des indices depuis un fichier texte\n",
    "def load_indices(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        indices = [line.strip() for line in f.readlines()]\n",
    "    return indices\n",
    "\n",
    "# Charger les indices pour train, test, val\n",
    "train_indices = load_indices(\"./train.txt\")\n",
    "test_indices = load_indices(\"./test.txt\")\n",
    "val_indices = load_indices(\"./val.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement sÃ©quences de mouvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:35.348384Z",
     "iopub.status.busy": "2025-01-31T06:08:35.348068Z",
     "iopub.status.idle": "2025-01-31T06:08:35.352732Z",
     "shell.execute_reply": "2025-01-31T06:08:35.351924Z",
     "shell.execute_reply.started": "2025-01-31T06:08:35.348355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_motion_sequences(sequence_dir, indices):\n",
    "    sequences = []\n",
    "    for idx in indices:\n",
    "        file_path = f\"{sequence_dir}/{idx}.npy\"\n",
    "        if os.path.exists(file_path):  # VÃ©rifie que le fichier existe\n",
    "            sequences.append(np.load(file_path))\n",
    "        else:\n",
    "            print(f\"Fichier manquant : {file_path}\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:38.326153Z",
     "iopub.status.busy": "2025-01-31T06:08:38.325880Z",
     "iopub.status.idle": "2025-01-31T06:08:38.330765Z",
     "shell.execute_reply": "2025-01-31T06:08:38.329907Z",
     "shell.execute_reply.started": "2025-01-31T06:08:38.326131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_sequences(sequences):\n",
    "    all_data = np.concatenate(sequences, axis=0)  # Combine toutes les sÃ©quences\n",
    "    mean = all_data.mean(axis=(0, 1))  # Moyenne globale sur frames et jointures\n",
    "    std = all_data.std(axis=(0, 1))   # Ã‰cart-type global\n",
    "\n",
    "    # Appliquer la normalisation\n",
    "    normalized_sequences = [(seq - mean) / std for seq in sequences]\n",
    "    return normalized_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:38.710877Z",
     "iopub.status.busy": "2025-01-31T06:08:38.710544Z",
     "iopub.status.idle": "2025-01-31T06:08:38.715830Z",
     "shell.execute_reply": "2025-01-31T06:08:38.714736Z",
     "shell.execute_reply.started": "2025-01-31T06:08:38.710852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_to_tensor(sequences, max_length=150):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) > max_length:  # Troncature si la sÃ©quence est trop longue\n",
    "            seq = seq[:max_length]\n",
    "        else:  # Padding si la sÃ©quence est trop courte\n",
    "            padding = np.zeros((max_length - len(seq), seq.shape[1], seq.shape[2]))\n",
    "            seq = np.vstack([seq, padding])\n",
    "        padded_sequences.append(seq)\n",
    "    \n",
    "    return torch.tensor(padded_sequences, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:08:41.969246Z",
     "iopub.status.busy": "2025-01-31T06:08:41.968936Z",
     "iopub.status.idle": "2025-01-31T06:11:32.311945Z",
     "shell.execute_reply": "2025-01-31T06:11:32.310985Z",
     "shell.execute_reply.started": "2025-01-31T06:08:41.969216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "train_sequences = load_motion_sequences(motion_data_dir, train_indices)\n",
    "train_sequences = [seq for seq in train_sequences if seq.ndim == 3 and seq.shape[0] > 1]\n",
    "train_sequences = normalize_sequences(train_sequences)\n",
    "train_tensor = convert_to_tensor(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:13:44.869530Z",
     "iopub.status.busy": "2025-01-31T06:13:44.869210Z",
     "iopub.status.idle": "2025-01-31T06:13:53.303285Z",
     "shell.execute_reply": "2025-01-31T06:13:53.302610Z",
     "shell.execute_reply.started": "2025-01-31T06:13:44.869502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "test_sequences = load_motion_sequences(motion_data_dir, test_indices)\n",
    "test_sequences = [seq for seq in test_sequences if seq.ndim == 3 and seq.shape[0] > 1]\n",
    "test_sequences = normalize_sequences(test_sequences)\n",
    "test_tensor = convert_to_tensor(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:14:19.927513Z",
     "iopub.status.busy": "2025-01-31T06:14:19.927224Z",
     "iopub.status.idle": "2025-01-31T06:14:54.002983Z",
     "shell.execute_reply": "2025-01-31T06:14:54.002275Z",
     "shell.execute_reply.started": "2025-01-31T06:14:19.927491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# val\n",
    "val_sequences = load_motion_sequences(motion_data_dir, val_indices)\n",
    "val_sequences = [seq for seq in val_sequences if seq.ndim == 3 and seq.shape[0] > 1]\n",
    "val_sequences = normalize_sequences(val_sequences)\n",
    "val_tensor = convert_to_tensor(val_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:15:26.766198Z",
     "iopub.status.busy": "2025-01-31T06:15:26.765908Z",
     "iopub.status.idle": "2025-01-31T06:15:26.771564Z",
     "shell.execute_reply": "2025-01-31T06:15:26.770895Z",
     "shell.execute_reply.started": "2025-01-31T06:15:26.766173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#vÃ©rification\n",
    "print(\"Val tensor:\", val_tensor.shape)\n",
    "print(\"Train tensor:\", train_tensor.shape)\n",
    "print(\"Test tensor:\", test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:15:28.438727Z",
     "iopub.status.busy": "2025-01-31T06:15:28.438419Z",
     "iopub.status.idle": "2025-01-31T06:15:29.633243Z",
     "shell.execute_reply": "2025-01-31T06:15:29.632473Z",
     "shell.execute_reply.started": "2025-01-31T06:15:28.438702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sauvegarge des tenseurs pour futurs imports\n",
    "# DÃ©finir les chemins de sauvegarde\n",
    "save_path = \"\"\n",
    "torch.save(val_tensor, save_path + \"val_tensor.pt\")\n",
    "torch.save(train_tensor, save_path + \"train_tensor.pt\")\n",
    "torch.save(test_tensor, save_path + \"test_tensor.pt\")\n",
    "\n",
    "print(\"Tenseurs sauvegardÃ©s avec succÃ¨s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import des tenseurs dÃ©jÃ  sauvegardÃ©s si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T20:09:58.586356Z",
     "iopub.status.busy": "2025-01-30T20:09:58.585945Z",
     "iopub.status.idle": "2025-01-30T20:10:07.806265Z",
     "shell.execute_reply": "2025-01-30T20:10:07.805218Z",
     "shell.execute_reply.started": "2025-01-30T20:09:58.586332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Charger les tenseurs\n",
    "train_tensor = torch.load(f\"./train_tensor.pt\")\n",
    "val_tensor = torch.load(f\"./val_tensor.pt\")\n",
    "test_tensor = torch.load(f\"./test_tensor.pt\")\n",
    "\n",
    "print(\"Tenseurs chargÃ©s !\")\n",
    "print(f\"Train Tensor: {train_tensor.shape}\")\n",
    "print(f\"Val Tensor: {val_tensor.shape}\")\n",
    "print(f\"Test Tensor: {test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des descriptions textuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:15:36.167002Z",
     "iopub.status.busy": "2025-01-31T06:15:36.166680Z",
     "iopub.status.idle": "2025-01-31T06:15:36.171913Z",
     "shell.execute_reply": "2025-01-31T06:15:36.171122Z",
     "shell.execute_reply.started": "2025-01-31T06:15:36.166972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_text_descriptions(text_dir, indices, max_sentences=3):\n",
    "    text_descriptions = {}  # Dictionnaire {id: [description1, description2, description3]}\n",
    "\n",
    "    for idx in indices:\n",
    "        file_path = os.path.join(text_dir, f\"{idx}.txt\")\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                lines = [line.split('#')[0].strip() for line in f.readlines() if line.strip()]\n",
    "                \n",
    "                # Garder jusqu'Ã  `max_sentences` phrases\n",
    "                text_descriptions[idx] = lines[:max_sentences]\n",
    "                \n",
    "        else:\n",
    "            print(f\"Avertissement : {idx}.txt introuvable\")\n",
    "    \n",
    "    return text_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:15:37.784108Z",
     "iopub.status.busy": "2025-01-31T06:15:37.783821Z",
     "iopub.status.idle": "2025-01-31T06:15:37.790604Z",
     "shell.execute_reply": "2025-01-31T06:15:37.789843Z",
     "shell.execute_reply.started": "2025-01-31T06:15:37.784087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MotionTextDataset(Dataset):\n",
    "    def __init__(self, motion_dict, text_descriptions_dict, tokenizer, max_length=50, multiple_sentences=False):\n",
    "        \"\"\"\n",
    "        Dataset associant les sÃ©quences de mouvements Ã  plusieurs descriptions textuelles.\n",
    "        \"\"\"\n",
    "        self.motions = motion_dict\n",
    "        self.text_descriptions = text_descriptions_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.indices = list(text_descriptions_dict.keys())  # Liste des indices valides\n",
    "        self.max_length = max_length\n",
    "        self.multiple_sentences = multiple_sentences  # Option pour gÃ©rer plusieurs phrases\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        \n",
    "        # RÃ©cupÃ©rer la sÃ©quence de mouvement\n",
    "        motion = self.motions[index]  # [Frames, Joints, Coordinates]\n",
    "\n",
    "        # RÃ©cupÃ©rer **les phrases associÃ©es** Ã  cet ID\n",
    "        text_list = self.text_descriptions[index]\n",
    "        \n",
    "        if self.multiple_sentences:\n",
    "            # **ConcatÃ©ner les phrases** en une seule avec un sÃ©parateur \". \"\n",
    "            text = \" \".join(text_list)\n",
    "        else:\n",
    "            # **Prendre uniquement la premiÃ¨re phrase**\n",
    "            text = text_list[0]\n",
    "\n",
    "        # Tokeniser le texte\n",
    "        tokenized_text = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"motion\": torch.tensor(motion, dtype=torch.float32),  # Convertir en tenseur PyTorch\n",
    "            \"input_ids\": tokenized_text[\"input_ids\"].squeeze(0),  \n",
    "            \"attention_mask\": tokenized_text[\"attention_mask\"].squeeze(0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel des descriptions/Tokenizer/initialisation du dataset MotionText/VÃ©rification du dataset et des tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:15:41.381240Z",
     "iopub.status.busy": "2025-01-31T06:15:41.380952Z",
     "iopub.status.idle": "2025-01-31T06:15:43.121211Z",
     "shell.execute_reply": "2025-01-31T06:15:43.120333Z",
     "shell.execute_reply.started": "2025-01-31T06:15:41.381217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # Ajouter un token de padding explicite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:15:45.304872Z",
     "iopub.status.busy": "2025-01-31T06:15:45.304525Z",
     "iopub.status.idle": "2025-01-31T06:18:35.920112Z",
     "shell.execute_reply": "2025-01-31T06:18:35.919393Z",
     "shell.execute_reply.started": "2025-01-31T06:15:45.304846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Charger les descriptions textuelles pour chaque dataset train/val\n",
    "train_descriptions = load_text_descriptions(text_data_dir, train_indices, max_sentences=3)\n",
    "val_descriptions = load_text_descriptions(text_data_dir, val_indices,max_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:18:38.980930Z",
     "iopub.status.busy": "2025-01-31T06:18:38.980611Z",
     "iopub.status.idle": "2025-01-31T06:18:39.227588Z",
     "shell.execute_reply": "2025-01-31T06:18:39.226504Z",
     "shell.execute_reply.started": "2025-01-31T06:18:38.980905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VÃ©rifier un Ã©chantillon alÃ©atoire\n",
    "sample_ids = random.sample(list(train_descriptions.keys()), 5)  # Prendre 5 IDs au hasard\n",
    "\n",
    "print(\"\\n **VÃ©rification des descriptions chargÃ©es**\")\n",
    "for idx in sample_ids:\n",
    "    print(f\"\\n ID {idx} :\")\n",
    "    for i, sentence in enumerate(train_descriptions[idx]):\n",
    "        print(f\"   âž Phrase {i+1} : {sentence}\")\n",
    "\n",
    "# VÃ©rifier le nombre moyen de phrases par sÃ©quence\n",
    "num_sentences = [len(desc) for desc in train_descriptions.values()]\n",
    "print(f\"\\n Moyenne de phrases par ID : {sum(num_sentences) / len(num_sentences):.2f}\")\n",
    "print(f\" Distribution : {set(num_sentences)} phrases par ID (attendu : {max_sentences})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:18:42.492947Z",
     "iopub.status.busy": "2025-01-31T06:18:42.492564Z",
     "iopub.status.idle": "2025-01-31T06:18:42.565418Z",
     "shell.execute_reply": "2025-01-31T06:18:42.564712Z",
     "shell.execute_reply.started": "2025-01-31T06:18:42.492920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  Associer chaque mouvement Ã  son ID de texte (en prenant toutes les phrases)\n",
    "indices_list = list(train_descriptions.keys())[:len(train_tensor)]  # Garder seulement les IDs qui existent\n",
    "indices_list_val = list(val_descriptions.keys())[:len(val_tensor)] \n",
    "\n",
    "#  CrÃ©er un dictionnaire {id_text: motion_tensor[i]} pour TRAIN\n",
    "train_tensor_filtered = {idx: train_tensor[i] for i, idx in enumerate(indices_list)}\n",
    "train_descriptions_filtered = {idx: train_descriptions[idx] for idx in indices_list}  #  Prendre toutes les phrases !\n",
    "\n",
    "#  CrÃ©er un dictionnaire {id_text: motion_tensor[i]} pour VALIDATION\n",
    "val_tensor_filtered = {idx: val_tensor[i] for i, idx in enumerate(indices_list_val)}\n",
    "val_descriptions_filtered = {idx: val_descriptions[idx] for idx in indices_list_val}  #  Prendre toutes les phrases !\n",
    "\n",
    "print(f\" Correspondance des indices corrigÃ©e pour TRAIN : {len(train_tensor_filtered)} sÃ©quences\")\n",
    "print(f\" Correspondance des indices corrigÃ©e pour VALIDATION : {len(val_tensor_filtered)} sÃ©quences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:18:45.735610Z",
     "iopub.status.busy": "2025-01-31T06:18:45.735299Z",
     "iopub.status.idle": "2025-01-31T06:18:45.741901Z",
     "shell.execute_reply": "2025-01-31T06:18:45.740929Z",
     "shell.execute_reply.started": "2025-01-31T06:18:45.735584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CrÃ©er le dataset avec les **donnÃ©es filtrÃ©es et plusieurs phrases**\n",
    "train_dataset = MotionTextDataset(train_tensor_filtered, train_descriptions_filtered, tokenizer, multiple_sentences=True)\n",
    "val_dataset = MotionTextDataset(val_tensor_filtered, val_descriptions_filtered, tokenizer, multiple_sentences=True)\n",
    "\n",
    "print(f\" Dataset d'entraÃ®nement : {len(train_dataset)} exemples\")\n",
    "print(f\" Dataset de validation : {len(val_dataset)} exemples\")\n",
    "\n",
    "batch_size = 64  # Ajustable selon la mÃ©moire GPU\n",
    "\n",
    "# CrÃ©er les DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\" DataLoaders crÃ©Ã©s avec succÃ¨s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:18:47.963289Z",
     "iopub.status.busy": "2025-01-31T06:18:47.962975Z",
     "iopub.status.idle": "2025-01-31T06:18:47.978247Z",
     "shell.execute_reply": "2025-01-31T06:18:47.977579Z",
     "shell.execute_reply.started": "2025-01-31T06:18:47.963260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def verify_text_descriptions(text_descriptions):\n",
    "    \"\"\"\n",
    "    VÃ©rifie que chaque ID possÃ¨de bien 3 phrases.\n",
    "    \"\"\"\n",
    "    count_per_id = {idx: len(texts) for idx, texts in text_descriptions.items()}\n",
    "    \n",
    "    #  VÃ©rifier combien d'IDs ont exactement 3 phrases\n",
    "    total_ids = len(count_per_id)\n",
    "    ids_with_3_sentences = sum(1 for count in count_per_id.values() if count == 3)\n",
    "    \n",
    "    print(f\" VÃ©rification des descriptions textuelles :\")\n",
    "    print(f\"  - Nombre total d'IDs : {total_ids}\")\n",
    "    print(f\"  - IDs avec exactement 3 phrases : {ids_with_3_sentences} ({(ids_with_3_sentences / total_ids) * 100:.2f}%)\")\n",
    "    \n",
    "    #  Afficher quelques exemples\n",
    "    print(\"\\n Exemples de descriptions :\")\n",
    "    for i, (idx, texts) in enumerate(text_descriptions.items()):\n",
    "        print(f\"  - ID {idx}: {texts}\")\n",
    "        if i == 4:  # Afficher seulement les 5 premiers exemples\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Tester sur les descriptions de train et validation\n",
    "verify_text_descriptions(train_descriptions)\n",
    "verify_text_descriptions(val_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:18:50.555484Z",
     "iopub.status.busy": "2025-01-31T06:18:50.555195Z",
     "iopub.status.idle": "2025-01-31T06:18:51.023134Z",
     "shell.execute_reply": "2025-01-31T06:18:51.022167Z",
     "shell.execute_reply.started": "2025-01-31T06:18:50.555461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VÃ©rification d'un batch\n",
    "for batch in train_loader:\n",
    "    print(\"Shape des sÃ©quences de mouvements :\", batch[\"motion\"].shape)  # [Batch, Frames, Joints, Coordinates]\n",
    "    print(\"Shape des tokens textuels :\", batch[\"input_ids\"].shape)  # [Batch, Max_Length]\n",
    "    print(\"Shape des masques d'attention :\", batch[\"attention_mask\"].shape)  # [Batch, Max_Length]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:18:52.947936Z",
     "iopub.status.busy": "2025-01-31T06:18:52.947580Z",
     "iopub.status.idle": "2025-01-31T06:19:06.182321Z",
     "shell.execute_reply": "2025-01-31T06:19:06.181567Z",
     "shell.execute_reply.started": "2025-01-31T06:18:52.947907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def verify_token_lengths(text_descriptions, tokenizer, max_length=50):\n",
    "    \"\"\"\n",
    "    VÃ©rifie le nombre de tokens gÃ©nÃ©rÃ©s par phrase et s'assure qu'ils ne dÃ©passent pas max_length.\n",
    "    \"\"\"\n",
    "    token_counts = []  # Stocke les longueurs des tokens\n",
    "\n",
    "    print(\" VÃ©rification du nombre de tokens par phrase...\")\n",
    "    \n",
    "    for idx, sentences in text_descriptions.items():\n",
    "        for sentence in sentences:  # On vÃ©rifie toutes les phrases associÃ©es Ã  un ID\n",
    "            tokens = tokenizer(sentence, truncation=False, padding=False)[\"input_ids\"]\n",
    "            token_counts.append(len(tokens))\n",
    "    \n",
    "    #  Statistiques globales\n",
    "    print(f\" Nombre total de phrases tokenisÃ©es : {len(token_counts)}\")\n",
    "    print(f\" Longueur moyenne des phrases tokenisÃ©es : {sum(token_counts) / len(token_counts):.2f}\")\n",
    "    print(f\" Nombre de phrases dÃ©passant {max_length} tokens : {sum(1 for t in token_counts if t > max_length)}\")\n",
    "\n",
    "    #  Afficher quelques exemples\n",
    "    print(\"\\n Exemples de phrases tokenisÃ©es :\")\n",
    "    for i, sentence in enumerate(list(text_descriptions.values())[0][:3]):  # 3 phrases du premier ID\n",
    "        tokens = tokenizer(sentence, truncation=False, padding=False)[\"input_ids\"]\n",
    "        print(f\"  - Phrase {i+1} ({len(tokens)} tokens) : {sentence}\")\n",
    "        print(f\"  - Tokens : {tokens}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Tester sur le dataset de TRAIN et VALIDATION\n",
    "verify_token_lengths(train_descriptions, tokenizer, max_length=50)\n",
    "verify_token_lengths(val_descriptions, tokenizer, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:19:06.224575Z",
     "iopub.status.busy": "2025-01-31T06:19:06.224308Z",
     "iopub.status.idle": "2025-01-31T06:19:06.631014Z",
     "shell.execute_reply": "2025-01-31T06:19:06.630081Z",
     "shell.execute_reply.started": "2025-01-31T06:19:06.224551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def verify_attention_masks(train_loader, tokenizer):\n",
    "    \"\"\"\n",
    "    VÃ©rifie que les tokens de padding sont bien ignorÃ©s par l'attention mask.\n",
    "    \"\"\"\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "\n",
    "        #  VÃ©rifier si des tokens padding existent dans input_ids\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        num_pad_tokens = (input_ids == pad_token_id).sum().item()\n",
    "\n",
    "        print(f\" VÃ©rification de l'attention mask :\")\n",
    "        print(f\"  - Nombre total de tokens dans le batch : {input_ids.numel()}\")\n",
    "        print(f\"  - Nombre de tokens de padding dÃ©tectÃ©s : {num_pad_tokens}\")\n",
    "        print(f\"  - Exemple de Input IDs : {input_ids[0].tolist()}\")\n",
    "        print(f\"  - Exemple de Attention Mask : {attention_mask[0].tolist()}\")\n",
    "        break  # On affiche seulement le premier batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Tester sur le TRAIN LOADER\n",
    "verify_attention_masks(train_loader, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Architecture du modÃ¨le**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:21:16.853364Z",
     "iopub.status.busy": "2025-01-31T06:21:16.853061Z",
     "iopub.status.idle": "2025-01-31T06:21:16.862907Z",
     "shell.execute_reply": "2025-01-31T06:21:16.862036Z",
     "shell.execute_reply.started": "2025-01-31T06:21:16.853341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MotionEncoderTransformer(nn.Module):\n",
    "    def __init__(self, joint_dim, coord_dim, hidden_dim=256, embedding_dim=512, hidden_size=768, num_layers=4, num_heads=8, ff_dim=None, dropout=0.1):\n",
    "        super(MotionEncoderTransformer, self).__init__()\n",
    "\n",
    "        self.noise_factor = 0.05\n",
    "        ff_dim = ff_dim or (hidden_dim * 4)  #  DÃ©faut : 4x hidden_dim si non spÃ©cifiÃ©\n",
    "\n",
    "        #  Convolutions 1D pour capturer les motifs locaux\n",
    "        self.conv1 = nn.Conv1d(in_channels=joint_dim * coord_dim, out_channels=hidden_dim, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        #  Normalisation & Dropout\n",
    "        self.layer_norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout_conv = nn.Dropout(dropout)\n",
    "\n",
    "        #  TransformerEncoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=ff_dim,  #  Utilisation de ff_dim ici\n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        #  Fully Connected\n",
    "        self.fc = nn.Linear(hidden_dim, embedding_dim)  \n",
    "\n",
    "        #  Projection vers GPT-2\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        #  Dropout final\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, J, C = x.shape\n",
    "        x = x.view(B, T, J * C).permute(0, 2, 1)  # [Batch, Features, Time]\n",
    "\n",
    "        #  Convolutions + Activation + Normalisation\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.layer_norm1(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.layer_norm2(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        #  Passage dans le Transformer Encoder\n",
    "        x = x.permute(0, 2, 1)  # [Batch, Time, Features]\n",
    "        x = self.transformer_encoder(x)  # [Batch, Time, Hidden_dim]\n",
    "        x = x[:, -1, :]  # Prendre le dernier Ã©tat de la sÃ©quence (comme LSTM)\n",
    "\n",
    "        #  Fully Connected + Activation\n",
    "        x = self.fc(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.02)  \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #  Projection vers GPT-2\n",
    "        x = self.projection(x)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        #  Ajout de bruit pour stabiliser\n",
    "        noise = torch.randn_like(x) * self.noise_factor\n",
    "        x = x + noise\n",
    "\n",
    "        #  Normalisation L2 finale\n",
    "        x = F.normalize(x, p=2, dim=-1) * 10\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:21:20.450906Z",
     "iopub.status.busy": "2025-01-31T06:21:20.450601Z",
     "iopub.status.idle": "2025-01-31T06:21:21.537833Z",
     "shell.execute_reply": "2025-01-31T06:21:21.536945Z",
     "shell.execute_reply.started": "2025-01-31T06:21:20.450884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = GPT2Config.from_pretrained(\"gpt2\", add_cross_attention=True) #  Charger GPT-2 avec Cross-Attention\n",
    "text_decoder = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config) # Charger sur CPU d'abord, puis transfÃ©rer sur GPU\n",
    "\n",
    "text_decoder = text_decoder.to(\"cuda\")\n",
    "text_decoder.resize_token_embeddings(len(tokenizer)) #  Mettre Ã  jour le modÃ¨le pour prendre en compte le nouveau token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:21:23.213512Z",
     "iopub.status.busy": "2025-01-31T06:21:23.213198Z",
     "iopub.status.idle": "2025-01-31T06:21:23.218943Z",
     "shell.execute_reply": "2025-01-31T06:21:23.218070Z",
     "shell.execute_reply.started": "2025-01-31T06:21:23.213484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TextDecoderTransformer(nn.Module):\n",
    "    def __init__(self, latent_dim=768, gpt2_model=\"gpt2\"):\n",
    "        super(TextDecoderTransformer, self).__init__()\n",
    "\n",
    "        self.gpt2 = GPT2LMHeadModel.from_pretrained(gpt2_model)\n",
    "\n",
    "        #  Ajout d'une projection vers GPT-2\n",
    "        self.latent_to_embedding = nn.Linear(latent_dim, self.gpt2.config.n_embd)\n",
    "        self.layer_norm = nn.LayerNorm(self.gpt2.config.n_embd)\n",
    "\n",
    "        #  Ajout dâ€™un Cross-Attention Layer\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=self.gpt2.config.n_embd, num_heads=8, batch_first=True)\n",
    "\n",
    "    def forward(self, latent_vector, input_ids, attention_mask):\n",
    "        #  Projection et normalisation du latent vector\n",
    "        transformed_vector = self.latent_to_embedding(latent_vector)\n",
    "        transformed_vector = self.layer_norm(transformed_vector).unsqueeze(1)  # [Batch, 1, Embedding_dim]\n",
    "\n",
    "        #  Passage dans Cross-Attention avant GPT-2\n",
    "        hidden_state, _ = self.cross_attention(transformed_vector, transformed_vector, transformed_vector)\n",
    "\n",
    "        #  Passage dans GPT-2\n",
    "        outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask, encoder_hidden_states=hidden_state)\n",
    "        return outputs.logits  # [Batch, Seq_Length, Vocab_Size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:21:25.548047Z",
     "iopub.status.busy": "2025-01-31T06:21:25.547757Z",
     "iopub.status.idle": "2025-01-31T06:21:25.552931Z",
     "shell.execute_reply": "2025-01-31T06:21:25.552193Z",
     "shell.execute_reply.started": "2025-01-31T06:21:25.548024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU disponible :\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Aucun GPU disponible. Le calcul se fera sur le CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T06:21:25.808310Z",
     "iopub.status.busy": "2025-01-31T06:21:25.808072Z",
     "iopub.status.idle": "2025-01-31T06:21:25.813011Z",
     "shell.execute_reply": "2025-01-31T06:21:25.812230Z",
     "shell.execute_reply.started": "2025-01-31T06:21:25.808289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VÃ©rifie si le GPU est disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Appareil utilisÃ© :\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T07:36:29.171089Z",
     "iopub.status.busy": "2025-01-31T07:36:29.170763Z",
     "iopub.status.idle": "2025-01-31T07:36:29.184701Z",
     "shell.execute_reply": "2025-01-31T07:36:29.183738Z",
     "shell.execute_reply.started": "2025-01-31T07:36:29.171057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mean_pooling(hidden_states, mask):\n",
    "    \"\"\"Moyenne des embeddings cachÃ©s en tenant compte du mask\"\"\"\n",
    "    mask_expanded = mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "    pooled = torch.sum(hidden_states * mask_expanded, dim=1) / (mask_expanded.sum(dim=1) + 1e-9)\n",
    "    return pooled.squeeze(1) if pooled.dim() == 3 else pooled\n",
    "\n",
    "def train_autoencoder(motion_encoder, text_decoder, train_loader, tokenizer, device=\"cuda\", num_epochs=10, lr=1e-4, gradient_accumulation_steps=1):\n",
    "    \n",
    "    #  DÃ©placer les modÃ¨les sur GPU et les mettre en mode entraÃ®nement\n",
    "    motion_encoder.to(device).train()\n",
    "    text_decoder.to(device).train()\n",
    "\n",
    "    #  Optimiseur (AdamW avec rÃ©gularisation plus forte)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        list(motion_encoder.parameters()) + list(text_decoder.parameters()), \n",
    "        lr=lr, weight_decay=0.02  #  LÃ©gÃ¨re augmentation du weight decay pour rÃ©gularisation\n",
    "    )\n",
    "\n",
    "    #  Scheduler dynamique (ReduceLROnPlateau)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True  #  Ajustement plus progressif du LR\n",
    "    )\n",
    "\n",
    "    #  Fonction de perte\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "    #  Normalisation des embeddings pour stabiliser\n",
    "    embedding_norm = torch.nn.LayerNorm(768).to(device)\n",
    "\n",
    "    #  Geler GPT-2 pendant les **4 premiÃ¨res Ã©poques**\n",
    "    for param in text_decoder.parameters():\n",
    "        param.requires_grad = False  \n",
    "\n",
    "    beta = 0.98  #  Moving Average pour la stabilisation de la loss\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        running_loss = 0  \n",
    "\n",
    "        #  Barre de progression `tqdm`\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\" Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for batch_idx, batch in progress_bar:\n",
    "            try:\n",
    "                #  Charger les donnÃ©es sur GPU\n",
    "                motions = batch[\"motion\"].to(device, non_blocking=True)\n",
    "                input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "\n",
    "                #  Encodage du mouvement avec Transformer Encoder\n",
    "                motion_embeddings = motion_encoder(motions)  # [Batch, Time, Hidden]\n",
    "                if motion_embeddings.dim() == 3:  \n",
    "                    motion_embeddings = mean_pooling(motion_embeddings, attention_mask)  # [Batch, Hidden]\n",
    "\n",
    "                motion_embeddings = embedding_norm(motion_embeddings)  # [Batch, Hidden]\n",
    "                motion_embeddings = motion_embeddings.unsqueeze(1)  # [Batch, 1, Hidden] pour GPT-2\n",
    "\n",
    "                #  Scheduled Sampling amÃ©liorÃ©\n",
    "                if epoch > 2 and loss.item() < 3.8:  #  DÃ©clenchement basÃ© sur la perte\n",
    "                    with torch.no_grad():\n",
    "                        sampled_ids = torch.argmax(text_decoder(\n",
    "                            input_ids=input_ids[:, :-1], \n",
    "                            attention_mask=attention_mask[:, :-1], \n",
    "                            encoder_hidden_states=motion_embeddings\n",
    "                        ).logits, dim=-1)\n",
    "                    \n",
    "                    mask = torch.rand_like(input_ids[:, :-1].float()) < 0.10  # ðŸ”¹ 10% remplacÃ©s par la prÃ©diction\n",
    "                    input_ids[:, :-1][mask] = sampled_ids[mask]\n",
    "\n",
    "                #  Passage dans GPT-2 (dÃ©codeur)\n",
    "                outputs = text_decoder(\n",
    "                    input_ids=input_ids[:, :-1],  \n",
    "                    attention_mask=attention_mask[:, :-1],\n",
    "                    encoder_hidden_states=motion_embeddings,\n",
    "                    labels=input_ids[:, 1:]  \n",
    "                )\n",
    "\n",
    "                logits = outputs.logits  # [Batch, Seq_Length, Vocab_Size]\n",
    "\n",
    "                #  Calcul de la perte\n",
    "                loss = criterion(logits.permute(0, 2, 1), input_ids[:, 1:])\n",
    "\n",
    "                #  Backpropagation avec Gradient Accumulation\n",
    "                loss.backward()\n",
    "                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(motion_encoder.parameters(), max_norm=5.0)  \n",
    "                    torch.nn.utils.clip_grad_norm_(text_decoder.parameters(), max_norm=5.0)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                running_loss = beta * running_loss + (1 - beta) * loss.item()\n",
    "                smoothed_loss = running_loss / (1 - beta ** (batch_idx + 1))\n",
    "\n",
    "                #  Mise Ã  jour de la barre de progression\n",
    "                progress_bar.set_postfix(loss=f\"{smoothed_loss:.4f}\")\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\" Erreur au batch {batch_idx + 1}: {e}\")\n",
    "                continue  \n",
    "\n",
    "        #  Mise Ã  jour du scheduler\n",
    "        scheduler.step(total_loss / max(1, len(train_loader)))  #  RÃ©duction du LR uniquement si la perte ne descend pas\n",
    "\n",
    "        #  DÃ©bloquer GPT-2 aprÃ¨s 4 epochs\n",
    "        if epoch == 4:\n",
    "            for param in text_decoder.parameters():\n",
    "                param.requires_grad = True  \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] *= 0.5  #  RÃ©duction du LR avant fine-tuning de GPT-2\n",
    "\n",
    "        #  Sauvegarde automatique du modÃ¨le\n",
    "        torch.save(motion_encoder.state_dict(), f\"motion_encoder_epoch_{epoch+1}.pth\")\n",
    "        torch.save(text_decoder.state_dict(), f\"text_decoder_epoch_{epoch+1}.pth\")\n",
    "        print(f\" ModÃ¨le sauvegardÃ© Ã  l'Ã©poque {epoch+1} !\")\n",
    "\n",
    "        #  Afficher la perte moyenne par Ã©poque\n",
    "        avg_loss = total_loss / max(1, len(train_loader))  \n",
    "        print(f\" Ã‰poque [{epoch+1}/{num_epochs}] - Perte moyenne : {avg_loss:.4f}\")\n",
    "\n",
    "    print(\" EntraÃ®nement terminÃ© avec succÃ¨s ! \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation de l'encoder et lancement de l'entraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T07:36:31.527585Z",
     "iopub.status.busy": "2025-01-31T07:36:31.527290Z",
     "iopub.status.idle": "2025-01-31T07:36:31.633736Z",
     "shell.execute_reply": "2025-01-31T07:36:31.632819Z",
     "shell.execute_reply.started": "2025-01-31T07:36:31.527561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "motion_encoder = MotionEncoderTransformer(\n",
    "    joint_dim=22,    # Nombre de jointures\n",
    "    coord_dim=3,     # CoordonnÃ©es x, y, z\n",
    "    hidden_dim=512,  #  AugmentÃ© pour plus de capacitÃ© de reprÃ©sentation\n",
    "    num_layers=6,    #  6 couches de Transformer Encoder\n",
    "    num_heads=8,     #  Multi-head attention (8 tÃªtes)\n",
    "    ff_dim=1024,     #  Feedforward dimension interne\n",
    "    dropout=0.1      # RÃ©gularisation\n",
    ").to(\"cuda\")  # Envoi sur le GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T07:36:32.251654Z",
     "iopub.status.busy": "2025-01-31T07:36:32.251314Z",
     "iopub.status.idle": "2025-01-31T07:36:32.263549Z",
     "shell.execute_reply": "2025-01-31T07:36:32.262908Z",
     "shell.execute_reply.started": "2025-01-31T07:36:32.251599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Simuler un batch de mouvements (batch_size=4, frames=150, joints=22, coords=3)\n",
    "dummy_motion = torch.randn(4, 150, 22, 3).to(\"cuda\")\n",
    "\n",
    "# Passer dans le MotionEncoder\n",
    "with torch.no_grad():\n",
    "    output_embedding = motion_encoder(dummy_motion)\n",
    "\n",
    "print(f\" MotionEncoder Output: {output_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RÃ©initialisation des poids de l'encodeur pour entraÃ®nement complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T07:36:32.629082Z",
     "iopub.status.busy": "2025-01-31T07:36:32.628768Z",
     "iopub.status.idle": "2025-01-31T07:36:32.636978Z",
     "shell.execute_reply": "2025-01-31T07:36:32.636083Z",
     "shell.execute_reply.started": "2025-01-31T07:36:32.629053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reset_model_weights(model):\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'reset_parameters'):\n",
    "            module.reset_parameters()\n",
    "\n",
    "# RÃ©initialiser uniquement le MotionEncoder\n",
    "reset_model_weights(motion_encoder)\n",
    "\n",
    "print(\" MotionEncoder rÃ©initialisÃ©, GPT-2 conservÃ© ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T07:36:35.732603Z",
     "iopub.status.busy": "2025-01-31T07:36:35.732296Z",
     "iopub.status.idle": "2025-01-31T07:36:36.186524Z",
     "shell.execute_reply": "2025-01-31T07:36:36.185560Z",
     "shell.execute_reply.started": "2025-01-31T07:36:35.732577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.keys())  # Doit contenir \"motion\", \"input_ids\", \"attention_mask\"\n",
    "    break\n",
    "\n",
    "assert next(motion_encoder.parameters()).is_cuda, \"MotionEncoder n'est pas sur GPU !\"\n",
    "assert next(text_decoder.parameters()).is_cuda, \"TextDecoder n'est pas sur GPU !\"\n",
    "assert tokenizer.pad_token_id is not None, \" pad_token_id non dÃ©fini dans le tokenizer !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T07:36:37.148784Z",
     "iopub.status.busy": "2025-01-31T07:36:37.148408Z",
     "iopub.status.idle": "2025-01-31T07:36:37.152955Z",
     "shell.execute_reply": "2025-01-31T07:36:37.152031Z",
     "shell.execute_reply.started": "2025-01-31T07:36:37.148750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "train_autoencoder(motion_encoder, text_decoder, train_loader, tokenizer, device=\"cuda\", num_epochs=10) # Quasi complÃ¨te convergence dÃ¨s 10 Ã©pochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sauvegarde du modÃ¨le final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T09:08:04.186215Z",
     "iopub.status.busy": "2025-01-31T09:08:04.185908Z",
     "iopub.status.idle": "2025-01-31T09:08:05.976515Z",
     "shell.execute_reply": "2025-01-31T09:08:05.975604Z",
     "shell.execute_reply.started": "2025-01-31T09:08:04.186188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  Sauvegarder le motion_encoder\n",
    "motion_encoder_path = \"/kaggle/working/motion_encoder\"\n",
    "torch.save(motion_encoder.state_dict(), motion_encoder_path)\n",
    "print(f\" Motion Encoder sauvegardÃ© sous : {motion_encoder_path}\")\n",
    "\n",
    "#  Sauvegarder le text_decoder\n",
    "text_decoder_path = \"/kaggle/working/text_decoder\"\n",
    "torch.save(text_decoder.state_dict(), text_decoder_path)\n",
    "print(f\" Text Decoder sauvegardÃ© sous : {text_decoder_path}\")\n",
    "\n",
    "#  Sauvegarder le tokenizer (Hugging Face)\n",
    "tokenizer_path = \"/kaggle/working/tokenizer\"\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "print(f\" Tokenizer GPT-2 sauvegardÃ© sous : {tokenizer_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GÃ©nÃ©ration des prÃ©dictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:07:37.892877Z",
     "iopub.status.busy": "2025-01-31T10:07:37.892569Z",
     "iopub.status.idle": "2025-01-31T10:07:37.900516Z",
     "shell.execute_reply": "2025-01-31T10:07:37.899795Z",
     "shell.execute_reply.started": "2025-01-31T10:07:37.892853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_descriptions(motion_encoder, text_decoder, tokenizer, tensors, indices, device=\"cuda\", max_new_tokens=17, mode=\"validation\"):\n",
    "    #  Mode Ã©valuation\n",
    "    motion_encoder.eval()\n",
    "    text_decoder.eval()\n",
    "\n",
    "    generated_descriptions = {}\n",
    "\n",
    "    # Liste des conjonctions et prÃ©positions qui indiquent une phrase incomplÃ¨te\n",
    "    invalid_endings = [\"and\", \"then\", \"as\", \"while\", \"with\", \"before\", \"after\", \"but\", \"so\"]\n",
    "\n",
    "    with torch.no_grad():  # Pas de calcul de gradient pour l'infÃ©rence\n",
    "        for i, (motion, idx) in enumerate(zip(tensors, indices)):\n",
    "            motion = motion.unsqueeze(0).to(device)  # Ajouter une dimension batch\n",
    "\n",
    "            #  1. Encoder le mouvement\n",
    "            motion_embedding = motion_encoder(motion)  # [1, 768]\n",
    "            motion_embedding = motion_embedding.unsqueeze(1)  # GPT-2 attend [Batch, 1, Hidden]\n",
    "\n",
    "            print(f\"motion_embedding {i}: mean={motion_embedding.mean().item()}, std={motion_embedding.std().item()}\")\n",
    "\n",
    "            #  2. DÃ©finir un prompt minimal\n",
    "            start_prompt = \"A person\"\n",
    "            input_ids = tokenizer(start_prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "            #  3. GÃ©nÃ©rer le texte avec des paramÃ¨tres optimisÃ©s\n",
    "            output = text_decoder.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,  # Plus de tokens pour Ã©viter une coupure trop tÃ´t\n",
    "                num_beams=5,  # Augmente la cohÃ©rence\n",
    "                encoder_hidden_states=motion_embedding,  \n",
    "                attention_mask=input_ids.new_ones(input_ids.shape),\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                do_sample=True,  \n",
    "                top_p=0.85,  # RÃ©duction de la diversitÃ© excessive\n",
    "                temperature=1.8,  # Moins de hasard pour de meilleures phrases\n",
    "                repetition_penalty=2.0,  # PÃ©nalise les rÃ©pÃ©titions sans supprimer des structures utiles\n",
    "                no_repeat_ngram_size=4  # Ã‰vite des rÃ©pÃ©titions longues\n",
    "            )\n",
    "\n",
    "            #  4. DÃ©coder les tokens\n",
    "            generated_text = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            #  Correction pour Ã©viter les rÃ©pÃ©titions et phrases mal formÃ©es\n",
    "            if not generated_text.lower().startswith(\"a person\"):\n",
    "                generated_text = \"A person \" + generated_text  # Ajout forcÃ©\n",
    "\n",
    "            #  Garder uniquement la premiÃ¨re phrase correcte\n",
    "            sentences = generated_text.split(\".\")\n",
    "            generated_text = sentences[0].strip() + \".\"\n",
    "\n",
    "            #  Assurer une bonne fin de phrase\n",
    "            last_word = generated_text.split()[-1].lower()\n",
    "            if last_word in invalid_endings:  # Si la phrase finit mal, on force une fin correcte\n",
    "                generated_text += \" They complete the movement.\"\n",
    "\n",
    "            #  Associer Ã  l'ID du mouvement\n",
    "            generated_descriptions[idx] = generated_text\n",
    "            print(f\" {mode.capitalize()} {i+1}/{len(tensors)} - GÃ©nÃ©rÃ© : {generated_text}\")\n",
    "\n",
    "    return generated_descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On sort les prÃ©dictions du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:07:39.346487Z",
     "iopub.status.busy": "2025-01-31T10:07:39.346012Z",
     "iopub.status.idle": "2025-01-31T10:11:57.863662Z",
     "shell.execute_reply": "2025-01-31T10:11:57.862933Z",
     "shell.execute_reply.started": "2025-01-31T10:07:39.346440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  GÃ©nÃ©rer les descriptions pour le test set\n",
    "\n",
    "test_descriptions = generate_descriptions(\n",
    "    motion_encoder, text_decoder, tokenizer, test_tensor, test_indices, device=\"cuda\",mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:16:24.159457Z",
     "iopub.status.busy": "2025-01-31T10:16:24.159147Z",
     "iopub.status.idle": "2025-01-31T10:16:24.167267Z",
     "shell.execute_reply": "2025-01-31T10:16:24.166568Z",
     "shell.execute_reply.started": "2025-01-31T10:16:24.159433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sauvegarder les prÃ©dictions brutes dans un CSV\n",
    "backup_df = pd.DataFrame({\n",
    "    'id': list(test_descriptions.keys()),\n",
    "    'text': list(test_descriptions.values())\n",
    "})\n",
    "\n",
    "# Enregistrer le fichier CSV\n",
    "backup_csv_path = \"/kaggle/working/test_descriptions_backup9.csv\"\n",
    "backup_df.to_csv(backup_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10929179,
     "sourceId": 91969,
     "sourceType": "competition"
    },
    {
     "sourceId": 219994917,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
